{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b5d085-30b8-4355-a7b3-686caa3a5fb2",
   "metadata": {},
   "source": [
    "## Modèles et Expérimentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6261472-1a9f-494f-bf2c-aa94bd65efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da05b690-800d-40ca-8b17-22f4d5f29a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samud\\Bureau\\Python code\\MVA\\NLP\\repo\\intro_NLP_projet\n",
      "NVIDIA GeForce GTX 1070 with Max-Q Design\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#  Packages  #\n",
    "##############\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import warnings\n",
    "import fasttext\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    DistilBertForSequenceClassification,\n",
    "    CamembertForSequenceClassification,\n",
    "    DistilBertTokenizerFast,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "############\n",
    "#  paths  #\n",
    "############\n",
    "\n",
    "root_path = Path(os.getcwd()).parents[0]\n",
    "print(root_path)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "\n",
    "################\n",
    "#  data paths  #\n",
    "################\n",
    "\n",
    "data_path = root_path.joinpath(\"data\")\n",
    "# pretrained_vec_path = data_path.joinpath(\"cc.fr.300.bin.gz\")\n",
    "\n",
    "###########\n",
    "#  utils  #\n",
    "###########\n",
    "\n",
    "def is_test_df(name):\n",
    "    return name.split(\"_\")[-1] == \"test\"\n",
    "\n",
    "def get_train_name(test_name):\n",
    "    return test_name.replace(\"test\", \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb4bfa-2904-4d41-9b93-eaf2f05b2f00",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd75cbb-c70d-4d40-9df5-737d53166f66",
   "metadata": {},
   "source": [
    "Suite aux travaux présents dans **1_Preprocessing** on dispose de 8 bases train, test avec ou sans preprocessing, gr (Humains) ou pr (OCR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0283c3-f943-4410-8fb8-f1a70fdfb9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame gr_raw_train : shape = (96, 3) \n",
      " columns = Index(['sex', 'text', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame gr_raw_test : shape = (145, 3) \n",
      " columns = Index(['sex', 'text', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame pr_raw_train : shape = (96, 3) \n",
      " columns = Index(['sex', 'text', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame pr_raw_test : shape = (145, 3) \n",
      " columns = Index(['sex', 'text', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame gr_proc_train : shape = (96, 6) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame gr_proc_test : shape = (145, 6) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame pr_proc_train : shape = (96, 6) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom'], dtype='object')\n",
      "\n",
      "DataFrame pr_proc_test : shape = (145, 6) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(data_path.joinpath(\"data_dict.pkl\"), 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "for name, df in data_dict.items():\n",
    "    print(f\"DataFrame {name} : shape = {df.shape} \\n columns = {df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6ed14-1d63-485a-a6eb-2b045fc96c64",
   "metadata": {},
   "source": [
    "## 1) un classifier statistique\n",
    "\n",
    "Ici on test notre score de feminite du noms issue de l'information statistique de **firstname_with_sex.csv**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218d9577-9ab3-4f21-89ec-5ddfe04ec530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat classifier on gr_raw_test : Accuracy =  0.9724137931034482\n",
      "Stat classifier on pr_raw_test : Accuracy =  0.9379310344827586\n",
      "Stat classifier on gr_proc_test : Accuracy =  0.9724137931034482\n",
      "Stat classifier on pr_proc_test : Accuracy =  0.9379310344827586\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#  utils  #\n",
    "###########\n",
    "\n",
    "def stat_pred(df, thrs = 0):\n",
    "    scores = df[\"feminite_nom\"]\n",
    "    pred = np.where( scores >=thrs, \"femme\", \"homme\")\n",
    "    pred[np.abs(scores)<0.1] = \"ambigu\"\n",
    "    return pred\n",
    "\n",
    "############\n",
    "#  script  #\n",
    "############\n",
    "\n",
    "for name, df in data_dict.items():\n",
    "    if is_test_df(name):\n",
    "        y_pred = stat_pred(df, thrs = 0)\n",
    "        y_true = df[\"sex\"]\n",
    "        print(f\"Stat classifier on {name} : Accuracy = \", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec75219-b209-406d-b382-4f418dd1ba60",
   "metadata": {},
   "source": [
    "Avec des bons features on est déjà à **97% d'accuracy** ! La moins bonne prédiction pour pr s'explique par le bruit des données et l'imperfection de la distance de Levenshtein comme mesure de similarité des noms. Pour combiner le classifier statistique aux modèles suivants, on ajoute les prédictions de se dernier dans la colonne **genre\\_nom**. Les résultats peuvent être différents entre raw et proc car les splits le sont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac751c68-20ef-4dd5-b5fe-e3013fcb1837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame gr_raw_train : shape = (96, 4) \n",
      " columns = Index(['sex', 'text', 'feminite_nom', 'genre_nom'], dtype='object')\n",
      "\n",
      "DataFrame gr_raw_test : shape = (145, 4) \n",
      " columns = Index(['sex', 'text', 'feminite_nom', 'genre_nom'], dtype='object')\n",
      "\n",
      "DataFrame pr_raw_train : shape = (96, 4) \n",
      " columns = Index(['sex', 'text', 'feminite_nom', 'genre_nom'], dtype='object')\n",
      "\n",
      "DataFrame pr_raw_test : shape = (145, 4) \n",
      " columns = Index(['sex', 'text', 'feminite_nom', 'genre_nom'], dtype='object')\n",
      "\n",
      "DataFrame gr_proc_train : shape = (96, 7) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom',\n",
      "       'genre_nom'],\n",
      "      dtype='object')\n",
      "\n",
      "DataFrame gr_proc_test : shape = (145, 7) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom',\n",
      "       'genre_nom'],\n",
      "      dtype='object')\n",
      "\n",
      "DataFrame pr_proc_train : shape = (96, 7) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom',\n",
      "       'genre_nom'],\n",
      "      dtype='object')\n",
      "\n",
      "DataFrame pr_proc_test : shape = (145, 7) \n",
      " columns = Index(['sex', 'nom', 'metier', 'lien_famille', 'civilite', 'feminite_nom',\n",
      "       'genre_nom'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#  ajout genre_nom  #\n",
    "#####################\n",
    "for name, df in data_dict.items():\n",
    "    df[\"genre_nom\"] = stat_pred(df, thrs = 0)\n",
    "    print(f\"DataFrame {name} : shape = {df.shape} \\n columns = {df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fffe1-97a8-4cb9-8417-0ad4b1cc8bb0",
   "metadata": {},
   "source": [
    "## 2) Fasttext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7831fc04-ec4e-4878-b3f9-762b9ee87aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#  Inputs  #\n",
    "############\n",
    "\n",
    "def _join_inputs(\n",
    "        df: pd.DataFrame, \n",
    "        cat_ft: List[str], \n",
    "        txt_ft: List[str], \n",
    "        sep_cat: str, \n",
    "        sep_txt: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Joins categorical and textual features in a DataFrame into a single column.\n",
    "    \n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): The input DataFrame containing the features.\n",
    "        - cat_ft (List[str]): A list of column names corresponding to the categorical features.\n",
    "        - txt_ft (List[str]): A list of column names corresponding to the textual features.\n",
    "        - sep_cat (str): The separator to use between categories when joining.\n",
    "        - sep_txt (str): The separator to use between words within each textual feature when joining.\n",
    "    \n",
    "        Returns:\n",
    "        - pd.DataFrame: The DataFrame with a new column \"joined_inputs\" containing the joined inputs.\n",
    "        \"\"\"\n",
    "        def join_from_dct(dct, sep):\n",
    "            return \" \".join([f\"{k}{sep}{v}\" for k, v in dct.items()])\n",
    "\n",
    "        join_from_dct = np.vectorize(join_from_dct)\n",
    "\n",
    "        def join_from_sub_df(lst, sep):\n",
    "            return join_from_dct(df[lst].to_dict(\"records\"), sep)\n",
    "\n",
    "        add_space = lambda s: s + \" \"\n",
    "\n",
    "        txt_arr = join_from_sub_df(txt_ft, sep_txt)\n",
    "        txt_arr = np.vectorize(add_space)(txt_arr)\n",
    "\n",
    "        if len(cat_ft) > 0 :\n",
    "            cat_arr = join_from_sub_df(cat_ft, sep_cat)\n",
    "            df[\"joined_inputs\"] = np.char.add(txt_arr, cat_arr)\n",
    "        else:\n",
    "            df[\"joined_inputs\"] = txt_arr\n",
    "\n",
    "        return df\n",
    "\n",
    "def _join_data(\n",
    "        df: pd.DataFrame, \n",
    "        y_vars: List[str], \n",
    "        label_code: str = \"__label__\"\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Joins the output labels and input features into a single column in a DataFrame.\n",
    "    \n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): The input DataFrame containing the features and output labels.\n",
    "        - y_vars (List[str]): A list of column names corresponding to the output labels.\n",
    "        - label_code (str): The prefix code to use for each output label.\n",
    "    \n",
    "        Returns:\n",
    "        - pd.DataFrame: The DataFrame with a new column \"joined_data\" containing the joined outputs and inputs.\n",
    "        \"\"\"\n",
    "        def aux(dct):\n",
    "            return \" \".join([f\"{label_code}{v}\" for k, v in dct.items()])\n",
    "\n",
    "        aux = np.vectorize(aux)\n",
    "\n",
    "        df[\"joined_outputs\"] = aux(df[y_vars].to_dict(\"records\"))\n",
    "        df[\"joined_data\"] = df[[\"joined_outputs\", \"joined_inputs\"]].agg(\n",
    "            \" \".join, axis=1\n",
    "        )\n",
    "        df[\"joined_data\"] = df[\"joined_data\"].str.replace(\"txt:\", \"\")\n",
    "        df = df.drop(columns=[\"joined_outputs\"])\n",
    "        return df\n",
    "\n",
    "def _save_fasttext_inputs_file(df, path):\n",
    "        df[\"joined_data\"].to_csv(\n",
    "            path,\n",
    "            index=False,\n",
    "            header=False,\n",
    "            sep=\";\",\n",
    "        )\n",
    "        # print(f\"Saving {path}\")\n",
    "\n",
    "def fasttext_transform(\n",
    "    df0: pd.DataFrame, \n",
    "    filename: str, \n",
    "    cat_fts: List[str], \n",
    "    txt_fts: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms the DataFrame into a format suitable for training with FastText.\n",
    "\n",
    "    This function preprocesses categorical and text features, joins them together, \n",
    "    and saves the resulting data to a FastText-compatible file.\n",
    "\n",
    "    Parameters:\n",
    "    - df0 (pd.DataFrame): The input DataFrame containing the features and output labels.\n",
    "    - filename (str): The filename to save the FastText-compatible file.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with transformed features and labels.\n",
    "    \"\"\"\n",
    "    df = df0.copy()\n",
    "    for cat_ft in cat_fts:\n",
    "        df[cat_ft] = df[cat_ft].astype(\"str\").fillna(\"\")\n",
    "    \n",
    "    df = _join_inputs(\n",
    "            df,\n",
    "            cat_fts,\n",
    "            txt_fts,\n",
    "            \":\",\n",
    "            \":\",\n",
    "        )\n",
    "    df = _join_data(\n",
    "        df,\n",
    "        [\"sex\"],\n",
    "    )\n",
    "    \n",
    "    if filename != \"\":\n",
    "        _save_fasttext_inputs_file(\n",
    "            df, data_path.joinpath( f\"{filename}.txt\")\n",
    "        )\n",
    "    return df\n",
    "\n",
    "#############\n",
    "#  Outputs  #\n",
    "#############\n",
    "\n",
    "def fasttext_fit(\n",
    "        kwargs,\n",
    "        pretrained_vec_path: str = \"\", \n",
    "    ):\n",
    "        kwargs[\"thread\"] = int(multiprocessing.cpu_count() / 3)\n",
    "        # print(\"Number of cores\", kwargs[\"thread\"])\n",
    "        if pretrained_vec_path != \"\":\n",
    "            kwargs[\"pretrainedVectors\"] = pretrained_vec_path\n",
    "            print(\"Pretrained\")\n",
    "        return fasttext.train_supervised(**kwargs)\n",
    "\n",
    "\n",
    "def fasttext_predict(df, model_trained):\n",
    "        label_code = \"__label__\"\n",
    "        outputs = model_trained.predict(list(df[\"joined_inputs\"]), k=1)\n",
    "\n",
    "        def clean_outputs(k, f):\n",
    "            name = [\"model_codes\", \"model_values\"][k]\n",
    "            df[name] = outputs[k]\n",
    "            df[name] = df[name].apply(np.vectorize(f))\n",
    "\n",
    "        clean_outputs(0, lambda s: s.replace(label_code, \"\"))\n",
    "        clean_outputs(1, float)\n",
    "        df[\"model_codes\"] = df[\"model_codes\"].apply(lambda lst: lst[0])\n",
    "\n",
    "###############\n",
    "#  Pipelines  #\n",
    "###############\n",
    "\n",
    "def fast_text_pipeline(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    cat_fts: List[str], \n",
    "    txt_fts: List[str], \n",
    "    filename: str, \n",
    "    kwargs: dict, \n",
    "    pretrained_vec_path: str = \"\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Pipeline for training and evaluating a FastText model.\n",
    "\n",
    "    This function preprocesses the training and testing DataFrames, trains a FastText model \n",
    "    on the training data, and evaluates the model on the testing data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train (pd.DataFrame): The training DataFrame.\n",
    "    - df_test (pd.DataFrame): The testing DataFrame.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "    - filename (str): The filename to save the FastText-compatible file during preprocessing.\n",
    "    - kwargs (dict): Additional keyword arguments to be passed to the `fasttext_fit` function.\n",
    "    - pretrained_vec_path (str): Path to the pretrained word vectors file (optional).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # on selectionne en fonction du cas proc ou raw \n",
    "    vars = set(df_train.columns)\n",
    "    cat_fts = list(set(cat_fts) & vars)\n",
    "    txt_fts = list(set(txt_fts) & vars)\n",
    "\n",
    "    # preprocessing avec sauvegarde\n",
    "    df_train_fasttext = fasttext_transform(df_train, filename, cat_fts, txt_fts)\n",
    "    df_test_fasttext = fasttext_transform(df_test, \"\", cat_fts, txt_fts)\n",
    "    \n",
    "    y_true = df_test_fasttext[\"sex\"]\n",
    "    fasttext_model = fasttext_fit(\n",
    "        kwargs,\n",
    "        pretrained_vec_path = pretrained_vec_path, \n",
    "    )\n",
    "    fasttext_predict(df_test_fasttext, fasttext_model)\n",
    "    score = accuracy_score(y_true, df_test_fasttext[\"model_codes\"])\n",
    "    print(f\"Accuracy test {filename}: {score:2f} \\n\")\n",
    "\n",
    "def fast_text_iter_pipeline(\n",
    "    data_dict: dict,\n",
    "    cat_fts: List[str], \n",
    "    txt_fts: List[str], \n",
    "    train_id: str, \n",
    "    kwargs: dict, \n",
    "    pretrained_vec_path: str = \"\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Iteratively performs FastText pipeline on multiple datasets.\n",
    "\n",
    "    This function iterates over the datasets provided in the `data_dict`, preprocesses \n",
    "    each dataset, and trains and evaluates a FastText model on it using the `fast_text_pipeline` function.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict (dict): A dictionary containing dataset names as keys and corresponding DataFrames as values.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "    - train_id (str): The identifier for the training dataset in the `data_dict`.\n",
    "    - kwargs (dict): Additional keyword arguments to be passed to the `fast_text_pipeline` function.\n",
    "    - pretrained_vec_path (str): Path to the pretrained word vectors file (optional).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for name, df in data_dict.items():\n",
    "        if is_test_df(name):\n",
    "            pref_name = \"_\".join(name.split(\"_\")[:-1])\n",
    "            filename = f\"{pref_name}_{train_id}\"\n",
    "            kwargs[\"input\"] = str(data_path.joinpath( f\"{filename}.txt\"))\n",
    "            df_train = data_dict[f\"{pref_name}_train\"]\n",
    "            fast_text_pipeline(\n",
    "                df_train,\n",
    "                df,\n",
    "                cat_fts, \n",
    "                txt_fts, \n",
    "                filename, \n",
    "                kwargs, \n",
    "                pretrained_vec_path=\"\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b73a54-c7a3-4095-be47-56ed30c4fe19",
   "metadata": {},
   "source": [
    "Après un peu de fine tuning, on fixe les paramètres d'entrainements identiques pour toutes les comparaisons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9c1ba63-849d-428d-8acb-c2a43b64f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== ['feminite_nom', 'genre_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_0: 0.972414 \n",
      "\n",
      "Accuracy test pr_raw_0: 0.937931 \n",
      "\n",
      "Accuracy test gr_proc_0: 0.965517 \n",
      "\n",
      "Accuracy test pr_proc_0: 0.937931 \n",
      "\n",
      "\n",
      "========== ['feminite_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_1: 0.855172 \n",
      "\n",
      "Accuracy test pr_raw_1: 0.524138 \n",
      "\n",
      "Accuracy test gr_proc_1: 0.896552 \n",
      "\n",
      "Accuracy test pr_proc_1: 0.834483 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_2: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_2: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_2: 0.903448 \n",
      "\n",
      "Accuracy test pr_proc_2: 0.793103 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_3: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_3: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_3: 0.889655 \n",
      "\n",
      "Accuracy test pr_proc_3: 0.772414 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_4: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_4: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_4: 0.903448 \n",
      "\n",
      "Accuracy test pr_proc_4: 0.827586 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_5: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_5: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_5: 0.903448 \n",
      "\n",
      "Accuracy test pr_proc_5: 0.827586 \n",
      "\n",
      "\n",
      "========== ['nom', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_6: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_6: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_6: 0.827586 \n",
      "\n",
      "Accuracy test pr_proc_6: 0.800000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_7: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_7: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_7: 0.910345 \n",
      "\n",
      "Accuracy test pr_proc_7: 0.793103 \n",
      "\n",
      "\n",
      "========== ['nom', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_8: 0.862069 \n",
      "\n",
      "Accuracy test pr_raw_8: 0.593103 \n",
      "\n",
      "Accuracy test gr_proc_8: 0.820690 \n",
      "\n",
      "Accuracy test pr_proc_8: 0.786207 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "        \"epoch\":200, \n",
    "        \"lr\":0.04, \n",
    "        \"dim\":100,\n",
    "        \"wordNgrams\":3,\n",
    "        }\n",
    "\n",
    "selection_to_test = [\n",
    "    ([\"feminite_nom\"], [\"genre_nom\", \"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([\"feminite_nom\"], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"text\"]),\n",
    "]\n",
    "\n",
    "i=0\n",
    "for cat_fts, txt_fts in selection_to_test:\n",
    "    print(\"\\n==========\",cat_fts+txt_fts, \"==========\\n\")\n",
    "    fast_text_iter_pipeline(\n",
    "        data_dict,\n",
    "        cat_fts, \n",
    "        txt_fts, \n",
    "        str(i), \n",
    "        kwargs, \n",
    "        pretrained_vec_path=\"\"\n",
    "    )\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b4100-4bbb-4f84-b70d-d37b51404c35",
   "metadata": {},
   "source": [
    "### Transfert learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d67b3f27-779e-4bf2-9a20-6d0b2c69871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== ['feminite_nom', 'genre_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p0: 0.972414 \n",
      "\n",
      "Accuracy test pr_raw_p0: 0.937931 \n",
      "\n",
      "Accuracy test gr_proc_p0: 0.965517 \n",
      "\n",
      "Accuracy test pr_proc_p0: 0.937931 \n",
      "\n",
      "\n",
      "========== ['feminite_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p1: 0.813793 \n",
      "\n",
      "Accuracy test pr_raw_p1: 0.524138 \n",
      "\n",
      "Accuracy test gr_proc_p1: 0.917241 \n",
      "\n",
      "Accuracy test pr_proc_p1: 0.827586 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p2: 0.682759 \n",
      "\n",
      "Accuracy test pr_raw_p2: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p2: 0.903448 \n",
      "\n",
      "Accuracy test pr_proc_p2: 0.793103 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p3: 0.682759 \n",
      "\n",
      "Accuracy test pr_raw_p3: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p3: 0.889655 \n",
      "\n",
      "Accuracy test pr_proc_p3: 0.765517 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p4: 0.675862 \n",
      "\n",
      "Accuracy test pr_raw_p4: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p4: 0.903448 \n",
      "\n",
      "Accuracy test pr_proc_p4: 0.813793 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p5: 0.675862 \n",
      "\n",
      "Accuracy test pr_raw_p5: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p5: 0.903448 \n",
      "\n",
      "Accuracy test pr_proc_p5: 0.813793 \n",
      "\n",
      "\n",
      "========== ['nom', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p6: 0.682759 \n",
      "\n",
      "Accuracy test pr_raw_p6: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p6: 0.841379 \n",
      "\n",
      "Accuracy test pr_proc_p6: 0.793103 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p7: 0.662069 \n",
      "\n",
      "Accuracy test pr_raw_p7: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p7: 0.910345 \n",
      "\n",
      "Accuracy test pr_proc_p7: 0.793103 \n",
      "\n",
      "\n",
      "========== ['nom', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_p8: 0.682759 \n",
      "\n",
      "Accuracy test pr_raw_p8: 0.641379 \n",
      "\n",
      "Accuracy test gr_proc_p8: 0.820690 \n",
      "\n",
      "Accuracy test pr_proc_p8: 0.779310 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "        \"epoch\":200, \n",
    "        \"lr\":0.03, \n",
    "        \"dim\":5,\n",
    "        \"wordNgrams\":3,\n",
    "        }\n",
    "\n",
    "selection_to_test = [\n",
    "    ([\"feminite_nom\"], [\"genre_nom\", \"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([\"feminite_nom\"], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"text\"]),\n",
    "]\n",
    "\n",
    "i=0\n",
    "for cat_fts, txt_fts in selection_to_test:\n",
    "    print(\"\\n==========\",cat_fts+txt_fts, \"==========\\n\")\n",
    "    fast_text_iter_pipeline(\n",
    "        data_dict,\n",
    "        cat_fts, \n",
    "        txt_fts, \n",
    "        \"p\"+str(i), \n",
    "        kwargs, \n",
    "        pretrained_vec_path=pretrained_vec_path\n",
    "    )\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb30b9-41d1-4ae6-9d19-5e1bbccb41fa",
   "metadata": {},
   "source": [
    "### 3) Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb67353-9455-4308-b2b5-31c55e4f4365",
   "metadata": {},
   "source": [
    "On teste ici 2 architectures préentrainées de type transformers. La première est DistilBERT une version synthétique de BERT et l'autre est CamemBERT une version française de RoBERTa qui est lui même une version plus robuste de BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e6f8b-1640-471d-b793-be825108cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4720002b-4b4e-4c3f-92b0-527e4ef206f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#  Inputs  #\n",
    "############\n",
    "\n",
    "def _join_inputs(\n",
    "        df: pd.DataFrame, \n",
    "        cat_ft: List[str], \n",
    "        txt_ft: List[str], \n",
    "        sep_cat: str, \n",
    "        sep_txt: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Joins categorical and textual features in a DataFrame into a single column.\n",
    "    \n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): The input DataFrame containing the features.\n",
    "        - cat_ft (List[str]): A list of column names corresponding to the categorical features.\n",
    "        - txt_ft (List[str]): A list of column names corresponding to the textual features.\n",
    "        - sep_cat (str): The separator to use between categories when joining.\n",
    "        - sep_txt (str): The separator to use between words within each textual feature when joining.\n",
    "    \n",
    "        Returns:\n",
    "        - pd.DataFrame: The DataFrame with a new column \"joined_inputs\" containing the joined inputs.\n",
    "        \"\"\"\n",
    "        def join_from_dct(dct, sep):\n",
    "            return \" \".join([f\"{k}{sep}{v}\" for k, v in dct.items()])\n",
    "\n",
    "        join_from_dct = np.vectorize(join_from_dct)\n",
    "\n",
    "        def join_from_sub_df(lst, sep):\n",
    "            return join_from_dct(df[lst].to_dict(\"records\"), sep)\n",
    "\n",
    "        add_space = lambda s: s + \" \"\n",
    "\n",
    "        txt_arr = join_from_sub_df(txt_ft, sep_txt)\n",
    "        txt_arr = np.vectorize(add_space)(txt_arr)\n",
    "\n",
    "        if len(cat_ft) > 0 :\n",
    "            cat_arr = join_from_sub_df(cat_ft, sep_cat)\n",
    "            df[\"joined_inputs\"] = np.char.add(txt_arr, cat_arr)\n",
    "        else:\n",
    "            df[\"joined_inputs\"] = txt_arr\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def torch_transform(\n",
    "    df0: pd.DataFrame,\n",
    "    cat_fts: List[str],\n",
    "    txt_fts: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms the input DataFrame into a format suitable for PyTorch training.\n",
    "\n",
    "    This function preprocesses the input DataFrame by converting categorical features\n",
    "    into string format and filling missing values. It then joins the input features\n",
    "    into a single text representation, and creates a new DataFrame containing the target \n",
    "    variable ('sex') encoded as binary ('sex_bin') and the joined input text ('text').\n",
    "\n",
    "    Parameters:\n",
    "    - df0 (pd.DataFrame): The input DataFrame containing the original data.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing the target variable encoded as binary ('sex_bin') \n",
    "      and the joined input text ('text').\n",
    "    \"\"\"\n",
    "    df = df0.copy()\n",
    "    for cat_ft in cat_fts:\n",
    "        df[cat_ft] = df[cat_ft].astype(\"str\").fillna(\"\")\n",
    "    df = _join_inputs(\n",
    "            df,\n",
    "            cat_fts,\n",
    "            txt_fts,\n",
    "            \":\",\n",
    "            \":\",\n",
    "        )\n",
    "\n",
    "    df2 = pd.DataFrame({\"sex\":  df[\"sex\"]})\n",
    "    df2[\"sex_bin\"] = (df[\"sex\"]==\"femme\").astype(\"int\")\n",
    "    df2[\"text\"] = df[\"joined_inputs\"]\n",
    "    return df2\n",
    "\n",
    "class GenderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for gender classification.\n",
    "\n",
    "    This class preprocesses the input DataFrame, tokenizes the text features using the provided tokenizer,\n",
    "    encodes the input data, and creates a dataset suitable for PyTorch training.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing the original data.\n",
    "    - tokenizer (PreTrainedTokenizer): The tokenizer object used to tokenize the text features.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "\n",
    "    Methods:\n",
    "    - __getitem__(self, idx): Gets the item at the specified index.\n",
    "    - __len__(self): Returns the length of the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer, cat_fts, txt_fts):\n",
    "        vars = set(df.columns)\n",
    "        cat_fts = list(set(cat_fts) & vars)\n",
    "        txt_fts = list(set(txt_fts) & vars)\n",
    "        df2 = torch_transform(df, cat_fts, txt_fts)\n",
    "        self.encodings = tokenizer(df2[\"text\"].to_list(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        self.labels = torch.tensor(df2[\"sex_bin\"].to_list())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def get_loaders(df_train, df_test, tokenizer, cat_fts, txt_fts):\n",
    "    train_dataset = GenderDataset(df_train, tokenizer, cat_fts, txt_fts)\n",
    "    test_dataset = GenderDataset(df_test, tokenizer, cat_fts, txt_fts)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "####################\n",
    "#  train and eval  #\n",
    "####################\n",
    "\n",
    "def train(device, train_loader, model, lr=5e-5, n_epochs = 3):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optim = AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total_loss += loss.item()\n",
    "        # if epoch%2==0:\n",
    "        #     print(f'Epoch {epoch+1}, Loss: {total_loss:1f}')\n",
    "\n",
    "def test(device, test_loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            output = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            for idx, logits in enumerate(output[\"logits\"]):\n",
    "                if torch.argmax(logits) == labels[idx]:\n",
    "                    correct += 1   \n",
    "                total += 1\n",
    "    accuracy = round(correct / total, 3)\n",
    "    return accuracy\n",
    "\n",
    "##############\n",
    "#  Pipeline  #\n",
    "##############\n",
    "\n",
    "def torch_pipeline(\n",
    "    device: torch.device,\n",
    "    model: torch.nn.Module,\n",
    "    tokenizer,\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    cat_fts: List[str], \n",
    "    txt_fts: List[str], \n",
    "    filename: str, \n",
    "    lr: float = 5e-5,\n",
    "    n_epochs: int = 3\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Torch pipeline for training and evaluating a PyTorch model for gender classification.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Prepares data loaders for training and testing.\n",
    "    2. Trains the model on the training data for the specified number of epochs.\n",
    "    3. Evaluates the trained model on the testing data and prints the accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - device (torch.device): The device on which to perform computations (e.g., \"cuda\" for GPU or \"cpu\").\n",
    "    - model (torch.nn.Module): The PyTorch model to be trained and evaluated.\n",
    "    - tokenizer: The tokenizer object used to tokenize the text features.\n",
    "    - df_train (pd.DataFrame): The DataFrame containing the training data.\n",
    "    - df_test (pd.DataFrame): The DataFrame containing the testing data.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "    - filename (str): The name of the file or dataset being processed.\n",
    "    - lr (float, optional): The learning rate for training the model (default: 5e-5).\n",
    "    - n_epochs (int, optional): The number of epochs for training the model (default: 3).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    train_loader, test_loader = get_loaders(df_train, df_test, tokenizer, cat_fts, txt_fts)\n",
    "    train(device, train_loader, model, lr=lr, n_epochs = n_epochs)\n",
    "    score = test(device, test_loader,  model)\n",
    "    print(f\"Accuracy test {filename}: {score:2f} \\n\")\n",
    "\n",
    "def torch_iter_pipeline(\n",
    "    device: torch.device,\n",
    "    model: torch.nn.Module,\n",
    "    tokenizer,\n",
    "    data_dict: Dict[str, pd.DataFrame],\n",
    "    cat_fts: List[str], \n",
    "    txt_fts: List[str], \n",
    "    train_id: str, \n",
    "    lr: float = 5e-5,\n",
    "    n_epochs: int = 3\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This function iterates over a dictionary of dataframes, where each dataframe represents a dataset\n",
    "    (e.g., train, test). For each test dataset, it trains and evaluates the model using the corresponding\n",
    "    training dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - device (torch.device): The device on which to perform computations (e.g., \"cuda\" for GPU or \"cpu\").\n",
    "    - model (torch.nn.Module): The PyTorch model to be trained and evaluated.\n",
    "    - tokenizer: The tokenizer object used to tokenize the text features.\n",
    "    - data_dict (Dict[str, pd.DataFrame]): A dictionary containing the datasets, where the keys represent\n",
    "      the dataset names and the values are pandas DataFrames.\n",
    "    - cat_fts (List[str]): A list of column names corresponding to the categorical features.\n",
    "    - txt_fts (List[str]): A list of column names corresponding to the text features.\n",
    "    - train_id (str): Identifier for the training dataset used in the filenames.\n",
    "    - lr (float, optional): The learning rate for training the model (default: 5e-5).\n",
    "    - n_epochs (int, optional): The number of epochs for training the model (default: 3).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for name, df in data_dict.items():\n",
    "        if is_test_df(name):\n",
    "            pref_name = \"_\".join(name.split(\"_\")[:-1])\n",
    "            filename = f\"{pref_name}_{train_id}\"\n",
    "            df_train = data_dict[f\"{pref_name}_train\"]\n",
    "            torch_pipeline(\n",
    "                device,\n",
    "                model,\n",
    "                tokenizer,\n",
    "                df_train,\n",
    "                df,\n",
    "                cat_fts, \n",
    "                txt_fts, \n",
    "                filename, \n",
    "                lr=lr,\n",
    "                n_epochs = n_epochs\n",
    "                \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61255b4c-0cdf-4ee3-9ff5-26f80772f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== ['feminite_nom', 'genre_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_0: 0.959000 \n",
      "\n",
      "Accuracy test pr_raw_0: 0.924000 \n",
      "\n",
      "Accuracy test gr_proc_0: 0.986000 \n",
      "\n",
      "Accuracy test pr_proc_0: 0.959000 \n",
      "\n",
      "\n",
      "========== ['feminite_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_1: 0.986000 \n",
      "\n",
      "Accuracy test pr_raw_1: 0.952000 \n",
      "\n",
      "Accuracy test gr_proc_1: 0.986000 \n",
      "\n",
      "Accuracy test pr_proc_1: 0.945000 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_2: 0.959000 \n",
      "\n",
      "Accuracy test pr_raw_2: 0.924000 \n",
      "\n",
      "Accuracy test gr_proc_2: 0.952000 \n",
      "\n",
      "Accuracy test pr_proc_2: 0.876000 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_3: 0.917000 \n",
      "\n",
      "Accuracy test pr_raw_3: 0.862000 \n",
      "\n",
      "Accuracy test gr_proc_3: 0.938000 \n",
      "\n",
      "Accuracy test pr_proc_3: 0.931000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_4: 0.959000 \n",
      "\n",
      "Accuracy test pr_raw_4: 0.924000 \n",
      "\n",
      "Accuracy test gr_proc_4: 0.972000 \n",
      "\n",
      "Accuracy test pr_proc_4: 0.917000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_5: 0.966000 \n",
      "\n",
      "Accuracy test pr_raw_5: 0.876000 \n",
      "\n",
      "Accuracy test gr_proc_5: 0.966000 \n",
      "\n",
      "Accuracy test pr_proc_5: 0.897000 \n",
      "\n",
      "\n",
      "========== ['nom', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_6: 0.952000 \n",
      "\n",
      "Accuracy test pr_raw_6: 0.890000 \n",
      "\n",
      "Accuracy test gr_proc_6: 0.952000 \n",
      "\n",
      "Accuracy test pr_proc_6: 0.862000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_7: 0.952000 \n",
      "\n",
      "Accuracy test pr_raw_7: 0.869000 \n",
      "\n",
      "Accuracy test gr_proc_7: 0.972000 \n",
      "\n",
      "Accuracy test pr_proc_7: 0.869000 \n",
      "\n",
      "\n",
      "========== ['nom', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_8: 0.945000 \n",
      "\n",
      "Accuracy test pr_raw_8: 0.848000 \n",
      "\n",
      "Accuracy test gr_proc_8: 0.938000 \n",
      "\n",
      "Accuracy test pr_proc_8: 0.890000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "selection_to_test = [\n",
    "    ([\"feminite_nom\"], [\"genre_nom\", \"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([\"feminite_nom\"], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"text\"]),\n",
    "]\n",
    "\n",
    "i=0\n",
    "for cat_fts, txt_fts in selection_to_test:\n",
    "    print(\"\\n==========\",cat_fts+txt_fts, \"==========\\n\")\n",
    "    torch_iter_pipeline(\n",
    "        device,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        data_dict,\n",
    "        cat_fts, \n",
    "        txt_fts, \n",
    "        str(i), \n",
    "        lr=5e-5,\n",
    "        n_epochs = 5\n",
    "    )\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc47a5f7-5c06-4769-8faa-537b1d4fabc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type camembert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== ['feminite_nom', 'genre_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_0: 0.986000 \n",
      "\n",
      "Accuracy test pr_raw_0: 0.938000 \n",
      "\n",
      "Accuracy test gr_proc_0: 0.972000 \n",
      "\n",
      "Accuracy test pr_proc_0: 0.931000 \n",
      "\n",
      "\n",
      "========== ['feminite_nom', 'nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_1: 0.972000 \n",
      "\n",
      "Accuracy test pr_raw_1: 0.938000 \n",
      "\n",
      "Accuracy test gr_proc_1: 0.986000 \n",
      "\n",
      "Accuracy test pr_proc_1: 0.952000 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_2: 0.917000 \n",
      "\n",
      "Accuracy test pr_raw_2: 0.855000 \n",
      "\n",
      "Accuracy test gr_proc_2: 0.883000 \n",
      "\n",
      "Accuracy test pr_proc_2: 0.890000 \n",
      "\n",
      "\n",
      "========== ['nom', 'metier', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_3: 0.931000 \n",
      "\n",
      "Accuracy test pr_raw_3: 0.862000 \n",
      "\n",
      "Accuracy test gr_proc_3: 0.924000 \n",
      "\n",
      "Accuracy test pr_proc_3: 0.890000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_4: 0.897000 \n",
      "\n",
      "Accuracy test pr_raw_4: 0.903000 \n",
      "\n",
      "Accuracy test gr_proc_4: 0.931000 \n",
      "\n",
      "Accuracy test pr_proc_4: 0.876000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_5: 0.917000 \n",
      "\n",
      "Accuracy test pr_raw_5: 0.855000 \n",
      "\n",
      "Accuracy test gr_proc_5: 0.876000 \n",
      "\n",
      "Accuracy test pr_proc_5: 0.841000 \n",
      "\n",
      "\n",
      "========== ['nom', 'civilite', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_6: 0.917000 \n",
      "\n",
      "Accuracy test pr_raw_6: 0.876000 \n",
      "\n",
      "Accuracy test gr_proc_6: 0.841000 \n",
      "\n",
      "Accuracy test pr_proc_6: 0.834000 \n",
      "\n",
      "\n",
      "========== ['nom', 'lien_famille', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_7: 0.897000 \n",
      "\n",
      "Accuracy test pr_raw_7: 0.862000 \n",
      "\n",
      "Accuracy test gr_proc_7: 0.931000 \n",
      "\n",
      "Accuracy test pr_proc_7: 0.917000 \n",
      "\n",
      "\n",
      "========== ['nom', 'text'] ==========\n",
      "\n",
      "Accuracy test gr_raw_8: 0.924000 \n",
      "\n",
      "Accuracy test pr_raw_8: 0.869000 \n",
      "\n",
      "Accuracy test gr_proc_8: 0.917000 \n",
      "\n",
      "Accuracy test pr_proc_8: 0.903000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "\n",
    "selection_to_test = [\n",
    "    ([\"feminite_nom\"], [\"genre_nom\", \"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([\"feminite_nom\"], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\", \"metier\", \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"civilite\",\"text\"]),\n",
    "    ([], [\"nom\",  \"lien_famille\", \"text\"]),\n",
    "    ([], [\"nom\",  \"text\"]),\n",
    "]\n",
    "\n",
    "i=0\n",
    "for cat_fts, txt_fts in selection_to_test:\n",
    "    print(\"\\n==========\",cat_fts+txt_fts, \"==========\\n\")\n",
    "    torch_iter_pipeline(\n",
    "        device,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        data_dict,\n",
    "        cat_fts, \n",
    "        txt_fts, \n",
    "        str(i), \n",
    "        lr=5e-5,\n",
    "        n_epochs = 15\n",
    "    )\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc3555-6761-4372-895c-4b26c4bde582",
   "metadata": {},
   "source": [
    "**L'analyse des résultats est réalisée dans le rapport.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
